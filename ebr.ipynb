{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import local_packages.ExampleBasedRigging as ebr\n",
    "import local_packages.tools3d_ as t3d\n",
    "\n",
    "import landmarks.LICT_narrow_r as LICT_narrow\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from qpsolvers import solve_qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Example - based facial rigging \n",
    "(https://lgg.epfl.ch/publications/2010/siggraph2010EBFR.pdf)\n",
    "\n",
    "Provided a set of generic blend shapes and a new face with a small number of scanned training poses (unconstrained expressions), the algorithm can progressively deform the generic blend shapes so that they can reproduce the training poses optimally during facial animation. In other words, the algorithm personalised the generic blend shapes to match the real expressions of any given face.   \n",
    "\n",
    "\n",
    "* All input data must share the same topology (same mesh). If you have a target face which is in a different topology than the generic blend shapes, use deformation transfer (https://github.com/vasiliskatr/deformation_transfer_ARkit_blendshapes) to create a set of generic blend shapes in the target topology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # # # # # # Example Based Rigging # # # # # # #           \n",
    "  \n",
    "# Get the landmarks which remain unaffected across different facial expressions.\n",
    "# This will enable the best alignement between meshes with variable expressions. \n",
    "skull_landmaks_target = LICT_narrow.LM[13::]\n",
    " \n",
    "\n",
    "print('Starting example based rigging for face ')  \n",
    "start_ebr = time.time()\n",
    "        \n",
    "# Parametrs chosen according to the original paper - refer to it for more details\n",
    "kappa = 0.1\n",
    "theta = 2\n",
    "n_iterations = 3\n",
    "distribution = np.flip(np.logspace(0.1, 1, n_iterations, endpoint=True))\n",
    "beta = t3d.normalise (distribution, 0.02, 0.09)\n",
    "gamma = t3d.normalise (distribution, 80, 1000)\n",
    "       \n",
    "    \n",
    "# # # # # # #        \n",
    "objpath_training_poses = 'data/training_poses/'\n",
    "objpath_target_neutral = 'data/training_poses/0.obj'\n",
    "objpath_personalised_bs = 'personalised_blendshapes/' \n",
    "\n",
    "# # # # # # # # # # # # # # Create matrices and structures before the main loop\n",
    "B_0, _, _, _ = t3d.Read(objpath_target_neutral, QuadMode = True)\n",
    "A_BS_model, B_BS_model, A_0, faces, n, bs_names = ebr.reading_generic_bs('data/generic_blendShapes/')\n",
    "n_vertices = A_0.shape[1]\n",
    "tri = faces.T \n",
    "num_triangles = tri.shape[0]\n",
    "S_training_poses, m = ebr.reading_training_data(objpath_training_poses)\n",
    "# Allign all training poses to neutral pose using 'skull' landmarks      \n",
    "for i in range (len(S_training_poses)):\n",
    "    S_training_poses[i] = t3d.align_target_to_source(S_training_poses[i], faces, skull_landmaks_target, B_0, faces, skull_landmaks_target) \n",
    "        \n",
    "Alpha_star = ebr.blend_shape_weights(A_0, B_0, A_BS_model, S_training_poses)\n",
    "A_0 = A_0.T\n",
    "B_0 = B_0.T\n",
    "\n",
    "A_BS_model = ebr.columnise(A_BS_model)\n",
    "A_BS_model = np.asarray(A_BS_model)\n",
    "\n",
    "S_training_poses = ebr.columnise(S_training_poses) \n",
    "M_A_star_f = ebr.make_M_A_star_fast(tri, A_0, B_0, A_BS_model)\n",
    "W_seed_f = ebr.make_W_seed_fast(tri, A_BS_model, kappa, theta)\n",
    "M_S_minus_M_B_0_f, M_B_0_f, M_S_f = ebr.make_M_S_minus_M_B_0_fast(S_training_poses, B_0, tri)\n",
    "A_sparse_recon = ebr.make_A_sparse_reconstruction(tri, n_vertices)\n",
    "  \n",
    "Alpha_optimum = Alpha_star.copy()\n",
    "\n",
    "# Main loop\n",
    "for opt_iteration in range(n_iterations):\n",
    "    \n",
    "    print('\\nOptimization Step: ' + str(opt_iteration))\n",
    "    print('Part A:')\n",
    "    print('Calculating new triangle local frames...')\n",
    "    start_temp = time.time()\n",
    "    I = np.eye(3)\n",
    "    A = sp.kron(Alpha_optimum, I)\n",
    "    M_B = np.zeros((n*3, 2*num_triangles))\n",
    "    M_B = ebr.lf_optimisation (num_triangles, A.A, M_S_minus_M_B_0_f, M_B, M_A_star_f, beta, gamma, W_seed_f, opt_iteration, n, m)\n",
    "    print (\"...done in \",(time.time() - start_temp), \"sec\") \n",
    "    print('\\nReconstructing vertex positions of unknown blendshapes from M_B...')\n",
    "    #RECONSTRUCTION\n",
    "    start = time.time()\n",
    "    reconstruction = [ebr.recon(M_B, A_sparse_recon, n_vertices, num_triangles, i) for i in range(n)]\n",
    "    for f in reconstruction:\n",
    "        idx = f[3]\n",
    "        B_BS_model[idx][0, :] = f[0]\n",
    "        B_BS_model[idx][1, :] = f[1]\n",
    "        B_BS_model[idx][2, :] = f[2]\n",
    "    \n",
    "    print (\"done in  \",(time.time() - start), \"sec\") \n",
    "    print('\\nPart B:')\n",
    "    print('Optimising blend shape weights...')\n",
    "    # Step B - Hold blendshapes  constant and solve for optimum weights\n",
    "    start_temp = time.time()\n",
    "    B_BS_model = np.asarray(B_BS_model)\n",
    "    B_All = B_BS_model.reshape(n, n_vertices*3)\n",
    "    B_All = B_All.T\n",
    "    for i in range(m): \n",
    "        Sj_minus_B0 = (S_training_poses[i]-B_0).T.reshape(n_vertices*3, 1)\n",
    "        qp_P = 2 * (B_All.T @ B_All + gamma[opt_iteration] * np.identity(n))\n",
    "        qp_q = -2 * (Sj_minus_B0.T @ B_All+ gamma[opt_iteration] * Alpha_star[i, :]).flatten()\n",
    "        qp_lb = np.zeros(n)\n",
    "        qp_ub = np.ones(n)\n",
    "        Alpha_optimum_temp = solve_qp(P=qp_P, q=qp_q, lb=qp_lb, ub=qp_ub)      \n",
    "        Alpha_optimum[i, :] = Alpha_optimum_temp\n",
    "    print (\"...done in \",(time.time() - start_temp), \"sec\") \n",
    "    Exp1 = B_0 + B_BS_model[13].T\n",
    "    t3d.ShowDeltaGrad(B_0.T,Exp1.T, faces)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "# save generated bs\n",
    "if not os.path.exists(objpath_personalised_bs):\n",
    "    os.makedirs(objpath_personalised_bs)\n",
    "i =0\n",
    "for delta in B_BS_model:\n",
    "    blend_shape = delta + B_0.T\n",
    "    blend_shape = t3d.align_target_to_source(blend_shape, faces, skull_landmaks_target,B_0.T, faces, skull_landmaks_target)\n",
    "    t3d.SaveObj(blend_shape, faces, objpath_target_neutral, save_destination = objpath_personalised_bs + bs_names[i] +'.obj' , CM=True)\n",
    "    i = i+1\n",
    "            \n",
    "print (\" All done in \",(time.time() - start_ebr), \" sec\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carv3d1",
   "language": "python",
   "name": "carv3d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
